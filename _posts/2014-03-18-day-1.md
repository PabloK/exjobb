---
layout: post
title:  "Day 1"
date:   2014-03-18
categories:
---

# Image quality analysis â€“ how is it done?

Detecting differences between the images is done in multiple ways.

## Subjective Assessment

A human is involved in evaluating an image. Not scalable.


## Objective Assessment

Objective assessment methods can be divided into three approaches: *full-reference*, *no-reference*, and *reduced-reference*. "[A] reference image [is] assumed to be error free and of highest quality. In reduced reference methods, features are extracted from the reference image and the method only compares this limited set of features with the image the quality of which has to be evaluated, which we will call *subject* image."

Read more in *Zhou Wang and Alan C. Bovik, Modern Image Quality Assessment. Morgan & Claypool Publish- ers, 2006*.

### Full-reference Methods

* Mean Square Error (MSE)
* Peak Signal to Noise Ratio (PSNR)
* Structural Similarity Index Map (SSIM)


### Reduced-reference

* Scale-Invariant Feature Transform (SIFT)

*See: Lowe, David G., Object recognition from local scale-invariant features, Proceedings of the International Conference on Computer Vision. 2. pp. 1150-1157. 1999.*


### No-reference

*See: Robert Herzog, Martin Cadik, Tunc O. Aydin, Kwang In Kim, Karol Myszkowski and Hans-P. Seidel, NoRM: No-Reference Image Quality Metric for Realistic Image Synthesis, The Eurographics Association and Blackwell Publishing Ltd., 2012.*


## Self Organizing Map (SOM)

[Amann et. al][amann et. al] suggests a SOM approach. It's basically a map of images that cluster together when they have similar features. This feature-based detection allows similar, but not exactly alike, images to be grouped together as the same type of image. In short it seems it works like the following.

1. Create a *feature-vector*. Basically it's an n-dimensional vector that stores a bunch of different features of the image, like color distribution, lightness, low-, mid-, and high-frequency gradient, edginess, and any other quantifiable thing.
2. Select which of the features are best suited to distinguish between a correct and an incorrect image.
3. Let the computer run through a batch of images and classify them as a particular type of image (correct, error-1, error-2, error-3, etc).

Also known as Kohonen map. See: *Kohonen, Teuvo. Self-Organized Formation of Topologically Correct Feature Maps. Biological Cybernetics 43 (1): 59-69. 1982.*

It is also suggested that other types of neural networks could be used to classify images.


# Challenges with multiple devices

## Collection of data

We want to test the output on multiple different devices, which encompasses multiple screen-sizes. So images will not necessarily be the same size. They *could* be by demanding the cnavas to be of a specific size; the smallest screen size would then dictate that size. It's not very likely, but a smaller screen size may need to be added at a later stage. Smaller screen size also reduces the amount of data that can be used.

What about adding a "magnifying glass"? Take a screenshot of a certain region with a specific size. Sweep over the scene similarly to how a CMOS-camera reads the sensor line-by-line.


## What types of errors should we expect to see?

The range of devices that run WebGL is pretty wide... computers, tablets, mobile phones, television sets, set-top boxes. So, we can't make too many assumptions regarding the hardware used to run a WebGL program. What varies? Memory size, processing power, more more more.


## Resources

* [Using Image Quality Assessment to Test Rendering Algorithms][amann et. al], Amann et. al
* [OpenCV][opencv] - Open Source Computer Vision

[amann et. al]: http://wscg.zcu.cz/wscg2013/program/full/E43-full.pdf
[opencv]: http://opencv.org